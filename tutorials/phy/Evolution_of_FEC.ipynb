{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uxb1X8tXkR3"
      },
      "source": [
        "# From GSM to 5G - The Evolution of Forward Error Correction\n",
        "\n",
        "This notebook compares the different FEC schemes from GSM via UMTS and LTE to 5G NR.\n",
        "Please note that a *fair* comparison of different coding schemes depends on many aspects such as:\n",
        "\n",
        " - Decoding complexity, latency, and scalability\n",
        "\n",
        "- Level of parallelism of the decoding algorithm and memory access patterns\n",
        "\n",
        "- Error-floor behavior\n",
        "\n",
        "- Rate adaptivity and flexibility\n",
        "\n",
        "## Table of Contents\n",
        "* [GPU Configuration and Imports](#GPU-Configuration-and-Imports)\n",
        "* [System Model](#System-Model)\n",
        "* [Error Rate Simulations](#Error-Rate-Simulations)\n",
        "* [Results for Longer Codewords](#Results-for-Longer-Codewords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Xi1ITAXkR8"
      },
      "source": [
        "## GPU Configuration and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T13:13:42.917551Z",
          "iopub.status.busy": "2025-03-09T13:13:42.916928Z",
          "iopub.status.idle": "2025-03-09T13:13:45.368486Z",
          "shell.execute_reply": "2025-03-09T13:13:45.367645Z"
        },
        "id": "Ff34w_vmXkR8",
        "outputId": "3b8f2838-9ba4-4b90-e7e1-23c603ace0a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Sionna and restarting the runtime. Please run the cell again.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
        "    gpu_num = 0 # Use \"\" to use the CPU\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# Import Sionna\n",
        "try:\n",
        "    import sionna.phy\n",
        "except ImportError as e:\n",
        "    import sys\n",
        "    if 'google.colab' in sys.modules:\n",
        "       # Install Sionna in Google Colab\n",
        "       print(\"Installing Sionna and restarting the runtime. Please run the cell again.\")\n",
        "       os.system(\"pip install sionna\")\n",
        "       os.kill(os.getpid(), 5)\n",
        "    else:\n",
        "       raise e\n",
        "\n",
        "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
        "# For more details, see https://www.tensorflow.org/guide/gpu\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Avoid warnings from TensorFlow\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "sionna.phy.config.seed = 42 # Set seed for reproducible random number generation\n",
        "\n",
        "# Load the required Sionna components\n",
        "from sionna.phy import Block\n",
        "from sionna.phy.mapping import Mapper, Demapper, Constellation, BinarySource\n",
        "from sionna.phy.fec.polar import Polar5GEncoder, Polar5GDecoder\n",
        "from sionna.phy.fec.ldpc import LDPC5GEncoder, LDPC5GDecoder\n",
        "from sionna.phy.fec.conv import ConvEncoder, ViterbiDecoder\n",
        "from sionna.phy.fec.turbo import TurboEncoder, TurboDecoder\n",
        "from sionna.phy.utils import ebnodb2no, hard_decisions, PlotBER\n",
        "from sionna.phy.channel import AWGN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T13:13:45.372380Z",
          "iopub.status.busy": "2025-03-09T13:13:45.371984Z",
          "iopub.status.idle": "2025-03-09T13:13:45.381389Z",
          "shell.execute_reply": "2025-03-09T13:13:45.380545Z"
        },
        "id": "Liueb7XvXkR-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm71cU8sXkR-"
      },
      "source": [
        "## System Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T13:13:45.385131Z",
          "iopub.status.busy": "2025-03-09T13:13:45.384810Z",
          "iopub.status.idle": "2025-03-09T13:13:45.395748Z",
          "shell.execute_reply": "2025-03-09T13:13:45.395008Z"
        },
        "id": "Afqa2DOhXkR-"
      },
      "outputs": [],
      "source": [
        "class System_Model(Block):\n",
        "    \"\"\"System model for channel coding BER simulations.\n",
        "\n",
        "    This model allows to simulate BERs over an AWGN channel with\n",
        "    QAM modulation. Arbitrary FEC encoder/decoder layers can be used to\n",
        "    initialize the model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        k: int\n",
        "            number of information bits per codeword.\n",
        "\n",
        "        n: int\n",
        "            codeword length.\n",
        "\n",
        "        num_bits_per_symbol: int\n",
        "            number of bits per QAM symbol.\n",
        "\n",
        "        encoder: Sionna Block\n",
        "            A Sionna Block that encodes information bit tensors.\n",
        "\n",
        "        decoder: Sionna Block\n",
        "            A Sionna Block that decodes llr tensors.\n",
        "\n",
        "        demapping_method: str\n",
        "            A string denoting the demapping method. Can be either \"app\" or \"maxlog\".\n",
        "\n",
        "        sim_esno: bool\n",
        "            A boolean defaults to False. If true, no rate-adjustment is done for the SNR calculation.\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "        batch_size: int or tf.int\n",
        "            The batch_size used for the simulation.\n",
        "\n",
        "        ebno_db: float or tf.float\n",
        "            A float defining the simulation SNR.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        (u, u_hat):\n",
        "            Tuple:\n",
        "\n",
        "        u: tf.float32\n",
        "            A tensor of shape `[batch_size, k] of 0s and 1s containing the transmitted information bits.\n",
        "\n",
        "        u_hat: tf.float32\n",
        "            A tensor of shape `[batch_size, k] of 0s and 1s containing the estimated information bits.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 k,\n",
        "                 n,\n",
        "                 num_bits_per_symbol,\n",
        "                 encoder,\n",
        "                 decoder,\n",
        "                 demapping_method=\"app\",\n",
        "                 sim_esno=False):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # store values internally\n",
        "        self.k = k\n",
        "        self.n = n\n",
        "        self.sim_esno = sim_esno # disable rate-adjustment for SNR calc\n",
        "\n",
        "        # number of bit per QAM symbol\n",
        "        self.num_bits_per_symbol = num_bits_per_symbol\n",
        "\n",
        "        # init components\n",
        "        self.source = BinarySource()\n",
        "\n",
        "        # initialize mapper and demapper for constellation object\n",
        "        self.constellation = Constellation(\"qam\",\n",
        "                                num_bits_per_symbol=self.num_bits_per_symbol)\n",
        "        self.mapper = Mapper(constellation=self.constellation)\n",
        "        self.demapper = Demapper(demapping_method,\n",
        "                                 constellation=self.constellation)\n",
        "\n",
        "        # the channel can be replaced by more sophisticated models\n",
        "        self.channel = AWGN()\n",
        "\n",
        "        # FEC encoder / decoder\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    @tf.function(jit_compile=True) # enable graph mode for increased throughputs\n",
        "    def call(self, batch_size, ebno_db):\n",
        "        return self.call_no_xla(batch_size, ebno_db)\n",
        "\n",
        "    # Polar codes cannot be executed with XLA\n",
        "    @tf.function(jit_compile=False) # enable graph mode\n",
        "    def call_no_xla(self, batch_size, ebno_db):\n",
        "\n",
        "        u = self.source([batch_size, self.k]) # generate random data\n",
        "\n",
        "        if self.encoder is None:\n",
        "            # uncoded transmission\n",
        "            c = u\n",
        "        else:\n",
        "            c = self.encoder(u) # explicitly encode\n",
        "\n",
        "        # calculate noise variance\n",
        "        if self.sim_esno:\n",
        "            no = ebnodb2no(ebno_db,\n",
        "                       num_bits_per_symbol=1,\n",
        "                       coderate=1)\n",
        "        else:\n",
        "            if self.encoder is None:\n",
        "                # uncoded transmission\n",
        "                coderate = 1\n",
        "            else:\n",
        "                coderate = self.k/self.n\n",
        "\n",
        "            no = ebnodb2no(ebno_db,\n",
        "                           num_bits_per_symbol=self.num_bits_per_symbol,\n",
        "                           coderate=coderate)\n",
        "\n",
        "        x = self.mapper(c) # map c to symbols x\n",
        "\n",
        "        y = self.channel(x, no) # transmit over AWGN channel\n",
        "\n",
        "        llr_ch = self.demapper(y, no) # demapp y to LLRs\n",
        "\n",
        "        if self.decoder is None:\n",
        "            # uncoded transmission\n",
        "            u_hat = hard_decisions(llr_ch)\n",
        "        else:\n",
        "            u_hat = self.decoder(llr_ch) # run FEC decoder (incl. rate-recovery)\n",
        "        return u, u_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK8A8fnTXkR_"
      },
      "source": [
        "## Error Rate Simulations\n",
        "\n",
        "We now compare the different schemes for a codeword length of $n=1024$ and coderate $r=0.5$.\n",
        "\n",
        "Let us define the codes to be simulated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T13:13:45.399539Z",
          "iopub.status.busy": "2025-03-09T13:13:45.399222Z",
          "iopub.status.idle": "2025-03-09T13:13:45.517045Z",
          "shell.execute_reply": "2025-03-09T13:13:45.516202Z"
        },
        "id": "q0akZEOfXkR_"
      },
      "outputs": [],
      "source": [
        "# code parameters\n",
        "k = 512 # number of information bits per codeword\n",
        "n = 1024 # desired codeword length\n",
        "codes_under_test = []\n",
        "\n",
        "# Uncoded transmission\n",
        "enc = None\n",
        "dec = None\n",
        "name = \"Uncoded QPSK\"\n",
        "codes_under_test.append([enc, dec, name])\n",
        "\n",
        "# Conv. code with Viterbi decoding\n",
        "enc = ConvEncoder(rate=1/2, constraint_length=5)\n",
        "dec = ViterbiDecoder(gen_poly=enc.gen_poly, method=\"soft_llr\")\n",
        "name = \"GSM: Convolutional Codes\"\n",
        "codes_under_test.append([enc, dec, name])\n",
        "\n",
        "# Turbo codes\n",
        "enc = TurboEncoder(rate=1/2, constraint_length=4, terminate=True)\n",
        "dec = TurboDecoder(encoder=enc, num_iter=8)\n",
        "name = \"UMTS/LTE: Turbo Codes\"\n",
        "codes_under_test.append([enc, dec, name])\n",
        "\n",
        "# LDPC codes\n",
        "enc = LDPC5GEncoder(k, n)\n",
        "dec = LDPC5GDecoder(encoder=enc, num_iter=40)\n",
        "name = \"5G: LDPC\"\n",
        "codes_under_test.append([enc, dec, name])\n",
        "\n",
        "# Polar codes\n",
        "enc = Polar5GEncoder(k, n)\n",
        "dec = Polar5GDecoder(enc, dec_type=\"hybSCL\", list_size=32)\n",
        "name = \"5G: Polar+CRC\"\n",
        "codes_under_test.append([enc, dec, name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAhDG73JXkSA"
      },
      "source": [
        "Generate a new BER plot figure to save and plot simulation results efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T13:13:45.520899Z",
          "iopub.status.busy": "2025-03-09T13:13:45.520593Z",
          "iopub.status.idle": "2025-03-09T13:13:45.524131Z",
          "shell.execute_reply": "2025-03-09T13:13:45.523482Z"
        },
        "id": "TSQW2pjXXkSA"
      },
      "outputs": [],
      "source": [
        "ber_plot = PlotBER(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr8V3cjfXkSA"
      },
      "source": [
        "And run the BER simulation for each code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T13:13:45.528127Z",
          "iopub.status.busy": "2025-03-09T13:13:45.527905Z",
          "iopub.status.idle": "2025-03-10T20:42:25.072660Z",
          "shell.execute_reply": "2025-03-10T20:42:25.071185Z"
        },
        "id": "-Kezsu5lXkSA"
      },
      "outputs": [],
      "source": [
        "num_bits_per_symbol = 2 # QPSK\n",
        "ebno_db = np.arange(0., 8, 0.2) # sim SNR range\n",
        "\n",
        "# run ber simulations for each code we have added to the list\n",
        "for code in codes_under_test:\n",
        "    print(\"\\n Running: \" + code[2])\n",
        "\n",
        "    # generate a new model with the given encoder/decoder\n",
        "    model = System_Model(k=k,\n",
        "                         n=n,\n",
        "                         num_bits_per_symbol=num_bits_per_symbol,\n",
        "                         encoder=code[0],\n",
        "                         decoder=code[1],\n",
        "                         sim_esno=False)\n",
        "\n",
        "    # run the Polar code in a separate call, as currently no XLA is supported\n",
        "    if not code[2]==\"5G: Polar+CRC\":\n",
        "        ber_plot.simulate(model, # the function have defined previously\n",
        "                        ebno_dbs=ebno_db, # SNR to simulate\n",
        "                        legend=code[2], # legend string for plotting\n",
        "                        max_mc_iter=1000, # run 1000 Monte Carlo runs per SNR point\n",
        "                        num_target_block_errors=2000, # continue with next SNR point after 1000 bit errors\n",
        "                        target_bler=3e-4,\n",
        "                        batch_size=10000, # batch-size per Monte Carlo run\n",
        "                        soft_estimates=False, # the model returns hard-estimates\n",
        "                        early_stop=True, # stop simulation if no error has been detected at current SNR point\n",
        "                        show_fig=False, # we show the figure after all results are simulated\n",
        "                        add_bler=True, # in case BLER is also interesting\n",
        "                        forward_keyboard_interrupt=False);\n",
        "    else:\n",
        "        # run model in non_xla mode\n",
        "        ber_plot.simulate(model.call_no_xla, # no XLA\n",
        "                         ebno_dbs=ebno_db, # SNR to simulate\n",
        "                         legend=code[2], # legend string for plotting\n",
        "                         max_mc_iter=10000, # we use more iterations with smaller batches\n",
        "                         num_target_block_errors=200, # continue with next SNR point after 1000 bit errors\n",
        "                         target_bler=3e-4,\n",
        "                         batch_size=1000, # batch-size per Monte Carlo run\n",
        "                         soft_estimates=False, # the model returns hard-estimates\n",
        "                         early_stop=True, # stop simulation if no error has been detected at current SNR point\n",
        "                         show_fig=False, # we show the figure after all results are simulated\n",
        "                         add_bler=True, # in case BLER is also interesting\n",
        "                         forward_keyboard_interrupt=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u54lcHDDXkSC"
      },
      "source": [
        "And show the final performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-10T20:42:25.076318Z",
          "iopub.status.busy": "2025-03-10T20:42:25.075698Z",
          "iopub.status.idle": "2025-03-10T20:42:25.570727Z",
          "shell.execute_reply": "2025-03-10T20:42:25.569919Z"
        },
        "id": "J0nxYqhRXkSC"
      },
      "outputs": [],
      "source": [
        "# remove \"(BLER)\" labels from legend\n",
        "for idx, l in enumerate(ber_plot.legend):\n",
        "    ber_plot.legend[idx] = l.replace(\" (BLER)\", \"\")\n",
        "\n",
        "# and plot the BLER\n",
        "ber_plot(xlim=[0, 7], ylim=[3.e-4, 1], show_ber=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-10T20:42:25.575771Z",
          "iopub.status.busy": "2025-03-10T20:42:25.575487Z",
          "iopub.status.idle": "2025-03-10T20:42:26.107700Z",
          "shell.execute_reply": "2025-03-10T20:42:26.106649Z"
        },
        "id": "UzOFyZToXkSC"
      },
      "outputs": [],
      "source": [
        "# BER\n",
        "ber_plot(xlim=[0, 7], ylim=[2.e-7, 1], show_bler=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6WjCoaMXkSC"
      },
      "source": [
        "## Results for Longer Codewords\n",
        "\n",
        "In particular for the data channels, longer codewords are usually required.\n",
        "For these applications, LDPC and Turbo codes are the workhorse of 5G and LTE, respectively.\n",
        "\n",
        "Let's compare LDPC and Turbo codes for $k=6144$ information bits and coderate $r=1/3$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-10T20:42:26.110080Z",
          "iopub.status.busy": "2025-03-10T20:42:26.109790Z",
          "iopub.status.idle": "2025-03-10T20:42:26.230442Z",
          "shell.execute_reply": "2025-03-10T20:42:26.229511Z"
        },
        "id": "29yiOYVpXkSC"
      },
      "outputs": [],
      "source": [
        "# code parameters\n",
        "k = 2048 # number of information bits per codeword\n",
        "n = 6156 # desired codeword length (including termination bits)\n",
        "codes_under_test = []\n",
        "\n",
        "# Uncoded QPSK\n",
        "enc = None\n",
        "dec = None\n",
        "name = \"Uncoded QPSK\"\n",
        "codes_under_test.append([enc, dec, name])\n",
        "\n",
        "#Turbo. codes\n",
        "enc = TurboEncoder(rate=1/3, constraint_length=4, terminate=True)\n",
        "dec = TurboDecoder(encoder=enc, num_iter=8)\n",
        "name = \"UMTS/LTE: Turbo Codes\"\n",
        "codes_under_test.append([enc, dec, name])\n",
        "\n",
        "# LDPC\n",
        "enc = LDPC5GEncoder(k, n)\n",
        "dec = LDPC5GDecoder(encoder=enc, num_iter=40)\n",
        "name = \"5G: LDPC\"\n",
        "codes_under_test.append([enc, dec, name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-10T20:42:26.232929Z",
          "iopub.status.busy": "2025-03-10T20:42:26.232686Z",
          "iopub.status.idle": "2025-03-10T20:42:26.235597Z",
          "shell.execute_reply": "2025-03-10T20:42:26.235138Z"
        },
        "id": "9PUrjL1pXkSD"
      },
      "outputs": [],
      "source": [
        "ber_plot_long = PlotBER(f\"Error Rate Performance (k={k}, n={n})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-10T20:42:26.238165Z",
          "iopub.status.busy": "2025-03-10T20:42:26.237942Z",
          "iopub.status.idle": "2025-03-10T21:58:37.334878Z",
          "shell.execute_reply": "2025-03-10T21:58:37.334107Z"
        },
        "id": "UgdfoYVXXkSD"
      },
      "outputs": [],
      "source": [
        "num_bits_per_symbol = 2 # QPSK\n",
        "ebno_db = np.arange(-1, 1.8, 0.1) # sim SNR range\n",
        "\n",
        "# run ber simulations for each code we have added to the list\n",
        "for code in codes_under_test:\n",
        "    print(\"\\n Running: \" + code[2])\n",
        "\n",
        "    # generate a new model with the given encoder/decoder\n",
        "    model = System_Model(k=k,\n",
        "                         n=n,\n",
        "                         num_bits_per_symbol=num_bits_per_symbol,\n",
        "                         encoder=code[0],\n",
        "                         decoder=code[1],\n",
        "                         sim_esno=False)\n",
        "\n",
        "    # the first argument must be a callable (function) that yields u and u_hat for batch_size and ebno\n",
        "    ber_plot_long.simulate(model, # the function have defined previously\n",
        "                     ebno_dbs=ebno_db, # SNR to simulate\n",
        "                     legend=code[2], # legend string for plotting\n",
        "                     max_mc_iter=1000, # run 100 Monte Carlo runs per SNR point\n",
        "                     num_target_block_errors=500, # continue with next SNR point after 2000 bit errors\n",
        "                     target_ber=6e-7,\n",
        "                     batch_size=10000, # batch-size per Monte Carlo run\n",
        "                     soft_estimates=False, # the model returns hard-estimates\n",
        "                     early_stop=True, # stop simulation if no error has been detected at current SNR point\n",
        "                     show_fig=False, # we show the figure after all results are simulated\n",
        "                     add_bler=True, # in case BLER is also interesting\n",
        "                     forward_keyboard_interrupt=False); # should be True in a loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-10T21:58:37.338405Z",
          "iopub.status.busy": "2025-03-10T21:58:37.338099Z",
          "iopub.status.idle": "2025-03-10T21:58:37.956436Z",
          "shell.execute_reply": "2025-03-10T21:58:37.955695Z"
        },
        "id": "LCJlWyy8XkSD"
      },
      "outputs": [],
      "source": [
        "# and show the figure\n",
        "ber_plot_long(xlim=[-1., 1.7],ylim=(6e-7, 1)) # we set the ylim to 1e-5 as otherwise more extensive simualtions would be required for accurate curves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHmOoBWhXkSD"
      },
      "source": [
        "A comparison of short length codes can be found in the tutorial notebook [5G Channel Coding Polar vs. LDPC Codes](5G_Channel_Coding_Polar_vs_LDPC_Codes.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP5Jr86ZXkSD"
      },
      "source": [
        "## Final Figure\n",
        "\n",
        "Combine results from the two simulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-10T21:58:37.964311Z",
          "iopub.status.busy": "2025-03-10T21:58:37.964093Z",
          "iopub.status.idle": "2025-03-10T21:58:39.680137Z",
          "shell.execute_reply": "2025-03-10T21:58:39.679338Z"
        },
        "id": "rSPfvN8CXkSD"
      },
      "outputs": [],
      "source": [
        "snrs = list(np.compress(a=ber_plot._snrs, condition=ber_plot._is_bler, axis=0))\n",
        "bers = list(np.compress(a=ber_plot._bers, condition=ber_plot._is_bler, axis=0))\n",
        "legends = list(np.compress(a=ber_plot._legends, condition=ber_plot._is_bler, axis=0))\n",
        "is_bler = list(np.compress(a=ber_plot._is_bler, condition=ber_plot._is_bler, axis=0))\n",
        "\n",
        "ylabel = \"BLER\"\n",
        "\n",
        "# generate two subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16,10))\n",
        "\n",
        "ax1.tick_params(axis='both', which='major', labelsize=18)\n",
        "ax2.tick_params(axis='both', which='major', labelsize=18)\n",
        "\n",
        "\n",
        "# Part A\n",
        "xlim=[0, 6]\n",
        "ylim=[1e-4, 1]\n",
        "\n",
        "ax1.set_xlim(xlim)\n",
        "ax1.set_ylim(ylim)\n",
        "\n",
        "for idx, b in enumerate(bers):\n",
        "    ax1.semilogy(snrs[idx], b, \"--\", linewidth=2)\n",
        "\n",
        "ax1.grid(which=\"both\")\n",
        "ax1.set_xlabel(r\"$E_b/N_0$ (dB)\", fontsize=25)\n",
        "ax1.set_ylabel(ylabel, fontsize=25)\n",
        "ax1.legend(legends, fontsize=20, loc=\"upper right\");\n",
        "ax1.set_title(\"$k=512, n=1024$\", fontsize=20)\n",
        "\n",
        "\n",
        "# remove \"(BLER)\" labels from legend\n",
        "for idx, l in enumerate(ber_plot_long.legend):\n",
        "    ber_plot_long.legend[idx] = l.replace(\" (BLER)\", \"\")\n",
        "\n",
        "snrs = list(np.compress(condition=ber_plot_long._is_bler, a=ber_plot_long._snrs, axis=0))\n",
        "bers = list(np.compress(condition=ber_plot_long._is_bler, a=ber_plot_long._bers, axis=0))\n",
        "legends = list(np.compress(condition=ber_plot_long._is_bler, a=ber_plot_long._legends, axis=0))\n",
        "is_bler = list(np.compress(condition=ber_plot_long._is_bler, a=ber_plot_long._is_bler, axis=0))\n",
        "\n",
        "\n",
        "# Part B\n",
        "xlim=[-1, 2]\n",
        "ylim=[1e-4, 1]\n",
        "\n",
        "ax2.set_xlim(xlim)\n",
        "ax2.set_ylim(ylim)\n",
        "ax2.set_title(\"$k=2048, n=6156$\", fontsize=20)\n",
        "\n",
        "# return figure handle\n",
        "#for idx, b in enumerate(bers):\n",
        "\n",
        "ax2.semilogy(snrs[0], bers[0], \"--\", linewidth=2, color=\"orange\")\n",
        "ax2.semilogy(snrs[1], bers[1], \"--\", linewidth=2, color=\"green\")\n",
        "ax2.semilogy(snrs[2], bers[2], \"--\", linewidth=2, color=\"blue\")\n",
        "\n",
        "ax2.grid(which=\"both\")\n",
        "ax2.set_xlabel(r\"$E_b/N_0$ (dB)\", fontsize=25)\n",
        "ax2.set_ylabel(ylabel, fontsize=25)\n",
        "plt.legend(legends, fontsize=20, loc=\"upper right\");"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "toc-autonumbering": false,
    "toc-showmarkdowntxt": false,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}