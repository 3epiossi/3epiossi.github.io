---
title: 邊緣運算的架構、平台
author: NastYboY
date: 2025-06-16
category: IOT
layout: post
mermaid: true
cover: /assets/images/IOT/edge_cover.png
---

# 邊緣的用途和定義
* 定義與本質：邊緣系統本質上是遠端計算系統，可視為常規IT管理組件的延伸，位於企業IT管理環境和資料中心之外。
  * 它借用了嵌入式系統、雲端計算、電腦安全和電信等既有工程領域的元素。
* 歷史淵源：遠端管理計算的最早形式可追溯到20世紀三四十年代，當時為管理廣泛分布的電力開關站而建立的遠端控制系統，後來發展成可程式邏輯控制器（PLC）。
* 近端邊緣與遠端邊緣：
  * 近端邊緣：作為遠端邊緣和雲端之間基礎設施的一部分，可與廣域網營運商的基礎設施共存，如基站和蜂窩交換站。
    * 它能承載SDWAN等複雜的計算服務。
  * 遠端邊緣：由能與雲端或近端邊緣設備通信、管理、資料交換的處理設備組成。
    * 它距離雲端最遠，最接近終端使用者或感測器系統，具有強即時性、安全關鍵設計和低延遲等要求，可作為大型個人區域網的網關。
* 邊緣計算的判斷標準：僅將感測器連接到遠端部署的電腦設備不算是邊緣計算。
  * 當感測器向雲端服務傳送資料，或人們玩互動式虛擬實境遊戲時，才是在使用邊緣計算設備，這些設備必須與集中式雲端服務協同工作。
* 資源與扇出：通常，離雲端越遠，計算系統的資源越緊張。
  * 將會有更多的終端（如藍牙感測器和SCADA系統）以非IP系統的形式遠離雲端，這種擴展稱為「扇出」（fan-out）。
* 相關術語：
  * 霧計算（Fog Computing）：一種雲服務架構，範圍從中央資料中心的雲系統到近端邊緣和遠端邊緣的設備。
    * 它表示地理位置上不同的一組雲和邊緣電腦的一個抽象集合，可以看成是單一實體。
* MEC（Multi-access Edge Computing）：以前稱為行動邊緣計算，由ETSI定義。
  * 它使低延遲、高頻寬和即時的應用能夠部署在大型網路的邊緣，並允許開發人員在電信營運商的無線存取網路（RAN）中執行應用程式。
* 微雲（Microcloud）：一個小型雲資料中心，類似於「盒子裡的雲」。
  * 它是一種支援客戶端-伺服器類型應用的資源密集型用例設備，類似於MEC的概念，旨在縮短回應時間並降低延遲，但不一定與電信或營運商基礎設施相關。

# 邊緣用例
* 資料增長趨勢：目前約有20%的企業資料在企業邊界外收集，Gartner預測到2023年將高達75%。
* 四種主要使用模式：
  * 低延遲（Low Latency）：邊緣系統部署在更靠近終端使用者和服務的地方，避免網路跳轉和傳輸延時，滿足雲遊戲、視訊串流等對延遲敏感的應用，以及需要即時決策或執行安全關鍵規則引擎的設備。
  * 頻寬限制（Bandwidth Constraints）：解決進/出邊緣系統的頻寬限制及雲或資料中心資料成本高昂的問題。
    * 邊緣計算透過過濾、快取、資料壓縮等技術有效提高可用頻寬。
  * 間歇性連接（Intermittent Connectivity）：針對不可靠的通信環境（如運輸物流應用），邊緣系統考慮使用本地快取來儲存資料，直到通信恢復，並可具備故障轉移或路由切換技術。
  * 安全和合規性（Security and Compliance）：涉及在傳入雲端或其他邊緣設備之前保護甚至刪除某些資料，特別是健康資料、影像或個人隱私。資料安全常由政府法規定義，可能涉及邊緣側大量的計算資源。

# 邊緣硬體架構
* 硬體類型與共性：邊緣系統可使用伺服器級刀鋒設備，或更類似於加固嵌入式電腦的遠端邊緣計算設備。
  * 所有現代計算設備都基於馮·諾伊曼架構，由計算單元、匯流排和記憶體組成。
* 典型片上系統（SOC）：圖8-2展示了一個具有兩個核心、嵌入式DSP和多個輸入/輸出模組的典型SOC互連結構示例。
處理器
  * 常見架構：包括x86（Intel和AMD）、ARM等，以及較少使用的MIPS、RISCV、SuperH、Sparc和PowerPC。
  * 處理速度和功率：
    * 時鐘速度：衡量處理器性能的基本單位，受限於熱量和工藝幾何過程。
    * 功率消耗：晶體管功率是器件工作頻率、內部電容和電壓平方的函數。
      * 提高頻率通常需增加電壓，不利於功耗。
    * 高結溫（TJ）：半導體器件正常工作的最高工作溫度，超過會發生離子遷移，使晶片失去半導體特性。
    * 熱保護：現代處理器會降低核心速度或安全關機以防止過熱損壞，如英特爾晶片中的熱監測器。
    * 邊緣考量：對遠端電子產品：降低頻率和電壓以延長電池壽命。
      * 對高性能工作負載：提升性能處理成像、電腦視覺和機器學習。
    * 暫存器（Registers）：最快的儲存方式，本質上是位於處理器管道附近的SRAM，可在一個時鐘周期內訪問。
      * ARM架構有16個暫存器，x86架構有16個通用暫存器。
      * ARM是載入-儲存類型，x86可直接操作記憶體。
  * 指令集架構（Instruction Set Architecture, ISA）：機器指令級的內部組合語言。
    * x86指令編碼與ARM不相容。
    * ISA規定了指令、功能和記憶體存取方式。
  * CISC（Complex Instruction Set Computer）與RISC（Reduced Instruction Set Computer）：
    * CISC指令較多，功能強大，但需要更多硬體支援。
    * RISC硬體架構更簡單高效，但更依賴編譯器和軟體執行複雜操作。
* 位元組順序（Byte Order）：表示數字時位元組的順序，分為大位元組序（MSB）和小位元組序（LSB）。
  * 在異構IoT系統中理解資料格式很重要，位元組順序轉換會導致嚴重的性能開銷。
* 核心數量和多執行緒：現代SOC常帶多個CPU核心。
  * 核心可獨立或相關聯，共享L2快取。
  * 從軟體和作業系統角度看，它們是單個邏輯CPU。
  * 若不同處理器或可程式實體的快取不一致，需軟體基礎的訊號量、共享記憶體技術或MPI。
* 處理器平行性（Processor Parallelism）：
  * 指令級平行性（Instruction-Level Parallelism, ILP）：透過管道實現，指令經過取指令、解碼、執行、記憶體、寫回等階段。
    * 增加管道級數可簡化電路並提高速度，但也可能增加風險。
* 執行緒級平行性（Thread-Level Parallelism, TLP）：透過多執行緒和超純量設計提高性能和功耗效率。
  * 超純量（Superscalar）：CPU指令級平行性的基本形式，使用多個獨立管道在一個週期內執行多條指令。
  * 粗粒度多執行緒（Coarse-grain multithreading）：執行緒在記憶體停頓時切換。
  * 細粒度多執行緒（Fine-grain multithreading）：在每個連續時鐘周期內在可用執行緒之間切換。
  * 多管道多執行緒（Multi-pipeline multithreading）：執行緒歸屬於特定管道，不會遷移。
  * 對稱多執行緒（Symmetric multithreading）：執行緒可在任何可用管道上執行，是執行緒級平行性的高級形式。
    * 通常可提升30%性能和功耗利用率，但需多執行緒軟體架構。
* 快取和儲存分層結構：處理器內建高速記憶體作為快取，分為L1、L2等層級。
  * L1最快，L2次之，可能跨多核共享。
  * 目的是將最近使用的資料放置在最接近指令執行管道的位置。
  * 快取是晶片成本最高的因素之一，佔用大量晶片面積。
  * 快取缺失（Cache Misses）：
    * 衝突型
    * 強制型
    * 容量型
    * 快取缺失代價高昂，特別是需要訪問主DRAM記憶體時。
      * 增加快取可提高性能，但成本也相應增加。
* 處理器的其他特性：
  * 推測執行/亂序執行（Speculative Execution / Out-of-Order Execution）：處理器內建機制，不遵循程式執行邏輯，硬體依據代碼追蹤、分支預測等對下一步指令做推測。
    * 依賴大量硬體支援，增加晶片面積和成本。
  * 浮點單元（Floating Point Unit, FPU）：常見於大型CPU設計，但並非全部都有。
    * 對機器學習、成像、視覺、數位訊號處理和統計數學等工作負載很重要。
    * 硬體FPU比浮點模擬快10～100倍。
  * 單指令多資料（Single Instruction Multiple Data, SIMD）：執行引擎，如Intel/AMD的SSE、AVX或ARM Neon。
    * 輔助協處理器，專用於處理媒體和批次資料工作負載。
    * 使用單條指令對寬度很廣的資料單元向量執行操作。
* 動態隨機存取記憶體和揮發性記憶體
  * 種類：邊緣系統中使用DRAM（DDR）、低功耗DDR（LPDDR）和圖形DDR（GDDR）等。
    * GDDR主要用於GPU硬體輔助功能，如成像、視覺和機器學習。
  * 錯誤校正碼記憶體（ECC Memory）：檢測並糾正DRAM記憶體中常見的故障，由宇宙射線、太陽耀斑或中子引起的「輕微翻轉」現象。
    * 海拔越高，影響越明顯。
* 儲存和非揮發性記憶體
  * 作用：儲存是許多邊緣系統的核心組件，可用作快取服務在通信失敗時保存資料，或保存從邊緣電腦到終端的資料流以減少延遲。
    * 由於邊緣系統可能無法固定連接，自我儲存管理很有必要。
  * 儲存分類和介面：
    * SATA（Serial AT Attachment）：傳統大容量儲存組件，廣泛應用，成本最低。
      * 速度從1.5 Gb/s發展到6 Gb/s，但吞吐量和延遲不如NVMe。
    * NVMe（Non-Volatile Memory Express）：使用PCI Express介面和優化協議與NAND快閃記憶體晶片通信。
      * 佔用空間更緊湊，提供最快/最低延遲解決方案。
    * eMMC（embedded MultiMediaCard）：消費電子產品典型應用，體積小、移動靈活，但性能或儲存密度不如其他介質。
    * USB：可連接儲存設備，使用NAND部件，透過USB匯流排連接。
      * 儲存容量可超過1 TB，傳輸速度可達20 Gb/s（USB 3.2）。
    * SPI Flash（Serial Peripheral Interface Flash）：低速SPI介面，由主機CPU訪問，主要適用於啟動和關鍵板載儲存。
      * 通常連接到可信平台模組（TPM）作為信任根保存啟動程式碼。
  * 儲存性能指標：
    * IOPS（Input/Output Operations Per Second）：每秒輸入/輸出，衡量儲存非連續性讀/寫請求。
    * DWPD（Drive Writes Per Day）：衡量儲存耐用性，尤其對NAND快閃記憶體重要，表示設備全部儲存容量每天可完全重寫的次數。
  * NAND快閃記憶體設計和注意事項：
    * 工作原理：基於「浮柵」原理的單元儲存，透過捕獲電子保存資料。
      * 寫入是「熱電子注入」，擦除是「福勒-諾德海姆隧穿效應」。
    * 類型：單層式（SLC）、多層式（MLC）、三層式（TLC）和四層式（QLC）。
      * 區別在於單個單元可支援儲存的位元數量。
      * 容量增加導致整體性能下降和使用壽命縮短。
    * 擦除次數限制：儲存單元擦除次數有限制，約3000至5000次，之後電氣特性會發生故障。
    * 磨損均衡（Wear Leveling）：緩解擦除次數限制的策略。
      * 動態磨損均衡：當新資料寫入儲存設備時，原始區塊標記為無效，寫入資料映射到新區塊。
        * 磨損均衡只在資料移動和重寫時發生。
      * 靜態磨損均衡：更先進，NAND設備上的所有資料都會被移動，以平衡某些檔案被重度重寫的影響，對於那些保持不變的資料，最終也會被移動到不同的物理頁面上。
  * 垃圾回收（Garbage Collection）：清除無效頁面，將一個區塊中所有「可用頁」讀取並遷移到新擦除的區塊中。
  * 過度配置（Over-provisioning）：在儲存器上預留額外的未使用空間。
    * 對於32 GB儲存器，實際可用區域為32,000,000,000位元組，而二進位形式的實際區域為32,073,741,824位元組，這提供了約7.37%的額外容量用於故障區塊和其他功能。
  * 寫入放大（Write Amplification）：垃圾回收和磨損均衡對沒有變化的資料塊進行重寫的現象。
    * 值越高，驅動器綜合磨損越嚴重。
  * Trim命令：作業系統發出的命令，告知SSD哪些空間可用，可減少寫入放大和磨損，提高處理性能。
* 低速I/O
  * 用途：用於連接串列快閃記憶體、微控制器和板載設備，以及IoT領域中的感測器和執行器。
  * 常見介面：
    * SPI（Serial Peripheral Interface）：同步低速通信介面，全雙工，主從關係，最高支援10 Mbit/s。
      * 用於TPM、LCD螢幕、安全數位儲存卡。
    * I2C（Inter-Integrated Circuit）：同步多主多從、基於分組的串列通信系統。
      * 典型用於與DRAM記憶體插槽中的DIMM模組通信，管理HDMI和VGA顯示資訊。速度範圍從100 Kbit/s到5 Mbit/s。
    * UART（Universal Asynchronous Receiver/Transmitter）：最簡單和最早的電腦通信方式之一，非同步串列雙線通信。
      * 只支援一個主站和一個從站，是SCADA IoT系統通信的基礎（如RS485或RS232）。
    * GPIO（General Purpose Input/Output）：片上系統或積體電路上的數位訊號引腳，沒有特定功能，可透過程式設計控制。
      * 可用作輸出驅動或捕獲輸入訊號，雙向或單向。
    * CAN（Controller Area Network）：車載標準同步匯流排架構，用於微控制器之間相互通信而無需主機。
      * 速度範圍從40～125 Kbit/s（低速容錯）到40 Kbit/s～1 Mbit/s（高速）。
* 高速I/O
  * 定義：任何傳輸速度約100 Mbit/s左右，或使用差分對等高級輸入輸出。
  * 常見互連：乙太網路收發器、USB介面和PCI Express匯流排。
    * PCIe（PCI Express）：晶片到晶片和外設互連的最常見形式。
      * 使用SerDes訊號，實現極高速通信，對雜訊和訊號偏移影響較小。
    * USB：更強大的即插即用設備互連首選，吞吐量低於PCIe，但選擇更多。
    * 乙太網路（Ethernet）：最早的規範，主要用於基於網路的通信。
* 硬體輔助和協處理
  * 形式：通常以GPU、DSP、模數轉換器等形式出現。
    * 伺服器級刀鋒系統使用分立組件，而嵌入式系統將硬體整合到單個片上系統或多模組晶片中。
  * 優點：硬體演算法比軟體處理快幾個數量級，功耗通常更低。
  * 應用：影像訊號處理
    * 圖形處理單元（GPGPU、機器學習加速、SIMD加速）
    * 數位訊號處理（音訊、即時訊號分析）
    * 壓縮和解壓縮
    * 加密加速器（AES、SHA）
    * 硬體輔助推論引擎（矩陣乘法、卷積神經網路加速）
  * 成本：增加晶片面積和硬體許可成本，對軟體和架構的資料流產生影響。
* 啟動和安全模組
  * TPM（Trusted Platform Module）：硬體模組，專用於驗證軟體、儲存加密金鑰和保護密碼。
  * 功能：信任根報告
    * 信任根儲存介面
    * 儲存金鑰
    * 產生亂數
    * 加密功能（加密/解密、簽名、金鑰認證、SHA-1、雜湊產生）
  * 啟動過程中的作用：訪問快閃儲存
    * 驗證第一個啟動階段的完整性
    * 在作業系統和其他載入組件完全受信任的啟動過程中驗證每個階段。
* 邊緣計算硬體示例
  * NXP設備（遠端計算，語音助手，移動車輛遠端通信處理電腦，低功耗，豐富低速I/O，散熱佳）
  * 研華（Advantech）邊緣電腦（耐用小型，惡劣環境，相容x86，完整Windows堆疊）
  * 超微（Supermicro）設備（1U資料中心刀鋒伺服器，最強計算能力，不適合惡劣環境）
* 防護等級（Ingress Protection, IP）
  * 目的：當硬體設備部署在環境條件無法控制的室外或任何區域時，保護電子設備免受污染、潮濕並減輕散熱問題。
  * 標準：國際慣例評定電子外殼硬度，稱為IP。
    * 測試產品抵禦水、灰塵和異物滲透的能力。
    * 相關標準包括MIL-STD-810（軍用）、RTCA/DO-160（航空無線電技術委員會）和IEC60529（國際電工委員會）。
  * IP等級編碼：兩位數編碼，第一位數表示防固體侵入，第二位數表示防水侵入。
    * 例如，IP65表示防塵且可防低壓水噴射，IP68表示防塵且可長時間完全浸泡在水中。

# 作業系統
* 重要性：作業系統的選擇是部署幾代軟體解決方案的基礎。
  * 它是硬體設備和應用程式之間的軟體抽象和保護層。
* 核心功能：提供應用程式二進位介面（ABI），即時響應和保障服務，形成軟體的行程級和執行緒級保護，為軟體應用程式之間提供共享記憶體和IO介面，管理系統記憶體和資源。
* 作業系統選擇要點
  * 考量因素：作業系統分發成本（公共許可如Linux vs. 商業許可如Windows）
    * 支援合同
    * 即時需求
    * 處理器架構支援（ARM, x86）
    * 處理器特性支援（虛擬記憶體、多級快取、SIMD擴展、浮點仿真）
    * 軟體包獲取方式
    * 軟體包數量
    * 設備引導方式
    * 內建安全服務
    * 記憶體和儲存大小精簡程度
    * 啟動時間
    * 檔案系統
    * 外圍硬體驅動支援
    * 通信/網路/協議棧支援
    * 是否需要使用者圖形介面（GUI）
  * 影響：作業系統是系統其他部分所依賴的基礎層，更改作業系統通常需要對軟體和驅動程式進行重大重構。
    * 容器化方法有助於抽象作業系統，但底層仍需要作業系統。
* 典型引導過程
  * Unix/Linux引導過程：圖8-11展示了從冷重設到使用者級提示的典型Linux變體引導過程。
  * TPM的作用：在開機時保障信任根，確保載入的第一段程式碼鏡像是合格、可信的。
  * 啟動方式：系統通常會執行開機自檢（POST）。
    * 傳統上使用BIOS，但現代系統使用可擴展韌體介面（EFI/UEFI）替代。
  * 核心初始化：EFI或GRUB載入作業系統映像並進入核心初始化後，使用臨時RAM磁碟協助排程引導行程。
    * 重要的步驟是執行各種運行級別（0到7），表示作業系統運行的特定模式。
* 作業系統調優
  * 精簡化原則：邊緣設備的基本映像構建理念是：
    * 只提供執行給定任務所需的最小軟體包和庫集。
    * 這不同於傳統雲端虛擬機安裝，後者預包裝了數千兆位元組的軟體包。
  * 邊緣側關注點：設備安全性、設備對環境的健壯性以及設備維護難度。
    * 非關鍵軟體包會消耗有限的儲存和記憶體資源。

# 邊緣平台
* 挑戰與解決方案：邊緣設備的遠端管理是個挑戰。
  * 現成的商用邊緣管理框架和基於容器的方法可以安全可控地將軟體部署到遠端邊緣電腦上。
* 軟體和系統期望：
  * 可重新映像（Remirrorability）
  * 中心管理和監控（Central Management）
  * 報告成功或失敗資訊（Reporting）
* 虛擬化
  * 虛擬化類型對比：
    * 全虛擬化（Full Virtualization）：硬體級別的抽象，在裸機上運行，使用虛擬機管理程式管理處理器上的一個或多個虛擬機。需要處理器和硬體支援虛擬化，如ARM Cortex A系列。
      * 分為類型1（直接在裸機上運行，如HyperV）
      * 類型2（有託管底層作業系統，如微軟虛擬PC）
    * 準虛擬化（Paravirtualization）：提供硬體抽象層（HAL），需要特殊驅動程式，透過超級呼叫訪問硬體。
      * 需修改客體作業系統以實現更高的性能。
  * 容器（Containers）：應用層級的抽象管理，沒有虛擬機管理程式或客體作業系統。
    * 只依賴宿主作業系統提供基本服務。彼此分離，提供類似虛擬機的防護，可動態分配記憶體。
    * 對邊緣計算特別有吸引力，輕便可移植，比傳統虛擬化更精簡、更節省資源，對資源受限設備很重要。
    * 支援CI/CD。
* 容器
  * 基本概念：一種將底層硬體和服務虛擬化的方法，位於作業系統層之上。
  * 核心定義：
    * 容器（Container）：容器映像的單一實例，一個主機上可有多個實例。
    * 映像（Image）：一組不包含狀態的檔案，但定義了容器的軟體包（或快照）。
    * Docker：建構和管理容器的工具。
      * 部署包括應用程式容器管理引擎和儲存庫。
      * 應用程式程式碼和所需依賴項（函式庫、二進位檔案、中介軟體等）聚合在一起組成了「胖二進位檔案」。
  * 容器化流程：選擇基準映像（如Ubuntu），創建Dockerfile（詳細說明如何建構映像），建構映像，然後在主機上執行命令部署和實例化生成的映像。
  * 優勢：極大地減輕了部署和開發工作量。
    * 允許使用持續整合/持續交付（CI/CD）等技術，使邊緣設備的開發模型如同大型軟體即服務（SaaS）解決方案的流程。
  * Microsoft Azure IoT Edge：
    * 功能：提供容器部署引擎和管理服務，可在Windows或Linux邊緣電腦上運行。
      * 提供免費開源運行時、Docker容器平台、相容的邊緣設備容器管理和部署流程、到Azure IoT Hub的雲端介面以及預配置服務。
      * 支援離線操作、快取、本地儲存資料、按需同步到雲端、端到端威脅保護和態勢管理、資料過濾/轉換。
    * 要求：支援x64、AMD64、ARM32v7或ARM64處理器
      * Linux或Windows作業系統
      * OCI相容容器運行時（Moby或Docker CE/EE）
      * 儲存、記憶體等資源
      * 透過MQTT或AMPQ協定回連到Azure IoT Hub的TCP/IP廣域網介面
    * 架構：Azure IoT Edge平台與雲端執行的Azure IoT Hub協同工作。
      * 邊緣運行時是輕量級的系統核心，管理模組/工作負載安裝、安全性、監控執行狀況和所有通信。
      * IoT Edge Agent：為管理模組服務。
      * IoT Edge Hub：管理通信，並作為Microsoft Azure IoT Hub的代理。
        * 維護一份清單，識別允許在邊緣設備上運行的合格和認證模組，並規定不同模組之間的路由規則。
        * 確保「至少一次」傳遞消息，並在通信問題或故障時本地儲存和快取所有消息。
    * 核心設計理念：某些專門設計在Azure雲上運行的服務和功能，如果滿足運行時最低要求，則可以在邊緣設備上本地運行
      * 如Azure函數、流分析、機器學習、自定義視覺服務和SQL資料庫作為IoT Edge模組運行。

# 邊緣計算用例
* 新興用途：環境計算和合成感測。
* 環境計算（Environmental Computing）
  * 概念：有時稱為普適計算，是人類與機器交互的一種模式。
    * 與傳統人機交互（透過監視器、鍵盤、滑鼠、觸控螢幕）不同，環境計算中沒有明顯的電腦可交互，交互的是所處的環境。
  * 本質：事物本身是計算結構的一部分，設備和人工智慧協同工作，在需要時提供幫助和服務，不需要時隱退。
    * 前端看不到任何典型電腦在發揮積極作用。
  * 實現方式：整合感測器、物聯網和邊緣計算，收集、分析、處理和執行環境中的資料。
    * 邊緣電腦的目標是在不產生干擾的情況下做到這一點，其物理結構應透明化。
  * 原則：
    * 不可見性（Invisibility）：系統不應引起人們的注意，技術在需要時可見，不需要時不可見。
    * 嵌入式智慧（Embedded Intelligence）：以感測器和計算的形式將智慧嵌入物體自身內部。
    * 無縫交互（Seamless Interaction）：旨在使複雜的交互與電腦無縫對接，將人而不是PC、滑鼠和鍵盤置於計算的中心。
    * 協同環境（Collaborative Environment）：由不同事物和對象組成的環境應協同工作和相互通信。
  * 範例：Amazon Alexa等語音助手和雲端連接設備，試圖在環境中部署，使用者可能甚至不知道邊緣電腦的存在，直到透過喚醒詞發出訊號。
  * 設計挑戰：建構一個能與人類交互但人類卻看不到的設備，即使邊緣系統具有強大的計算能力
    * 也要使其物理結構透明化，設計時考慮外形、空間、聲音和視覺（沒有閃爍的燈光、高速風扇、礙眼的布線）。
  * 合成感測：環境計算的一個很好的例子。
* 合成感測（Synthetic Sensing）
  * 提出者：Gierad Laput、Yang Zhang和Chris Harrison。
  * 概念：一個設備放置在環境中，依據內建在邊緣電腦中的不同感測器（如加速度計、溫度感測器、聲壓感測器等），訓練學習正在發生的事情。
    * 例如，學習火爐上的哪個燃燒器被點著、洗碗機是否正在運行、水龍頭是否打開。
  * 工作流程：多個感測器將資料匯聚到一台邊緣電腦上，透過一個訓練有素的推論引擎對即時訊號進行處理和整理，用以檢測事件。
    * 此類系統通常不使用視訊或攝影機資料。
  * 資料處理：邊緣設備獲取感測器資料後，首先消除訊號中的雜訊和偏差。
    * 接著對所收集資料的時基和時間戳進行歸一化處理，將多個樣本調整到一個共同的衍生時基。
    * 校正後，邊緣設備在接近即時的資料上執行訓練有素的推論模型，最終產品是環境所處狀態的分類。
  * 硬體示例：可使用類似粒子光子開發板的設備
    * 內建ST Micro STM32F205微控制器
    * 旨在將盡可能多的與時間相關的感測器輸入融合在一個模組中
  * 感測器範例：Grideye AMG833（紅外水平）
    * AMS TCS34725（顏色和亮度）
    * Xtrinsic MAG3110（三軸磁力儀）
    * Bosch BM280（溫度、氣壓計和濕度）
    * TDK Invensense MPU6500（六軸陀螺儀和加速度計）
    * 2.4 GHz Wi-Fi檢測RSSI場強變化、Panasonic AMN2111（PIR運動感測器）
    * 模擬ADMP401 MEMS麥克風感測器
    * 100 mH電感EMI感測器
  * 設計目標：遵循環境計算模式，創建一個以使用者為中心的空間感應設備，隱藏起來，向房主或企業主提供有用的環境狀態資訊，而不需要將過多的感測器和設備連接到每個對象上。